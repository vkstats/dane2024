[
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Design and Analysis of Networked Experiments 2024",
    "section": "About",
    "text": "About\nRegister to participate. Deadline has been extended to Friday 5 July.\nDesign and analysis of networked experiments is a novel area of research which finds practical use in most research disciplines, medical trials and industrial settings that involve connected experimental units. This workshop brings together leading researchers of the field of design and analysis of networked experiments. The aim is to enable in-depth discussions and initiate synergies between two dominant philosophies in networked experiments, optimal design and causal inference.\nThis workshop is in person and it is open to academic and industrial researchers/practitioners in the areas of design and analysis of experiments, casual inference, combinatorics and networks.\nThe conference is organised by Dr Vasiliki Koutra."
  },
  {
    "objectID": "index.html#keynote-speakers",
    "href": "index.html#keynote-speakers",
    "title": "Design and Analysis of Networked Experiments 2024",
    "section": "Keynote speakers",
    "text": "Keynote speakers\n\nDr Dean Eckles (MIT)\nDr Alexander Volfovsky (Duke University)\nProfessor Rosemary Bailey (University of St Andrews)\nDr Nathaniel Stevens (University of Waterloo)"
  },
  {
    "objectID": "index.html#sponsors",
    "href": "index.html#sponsors",
    "title": "Design and Analysis of Networked Experiments 2024",
    "section": "Sponsors",
    "text": "Sponsors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis workshop is supported by the London Mathematical Society. LMS believes that all parents working in mathematics should be able to attend conferences/research meetings without being hindered by childcare costs and thereby administers a Childcare Supplementary Grant Scheme. Further information about this scheme can be found on the LMS website: http://www.lms.ac.uk/content/childcare-supplementary-grants"
  },
  {
    "objectID": "programme.html",
    "href": "programme.html",
    "title": "Design and Analysis of Networked Experiments 2024",
    "section": "",
    "text": "All scientific sessions are in the River room. Coffee, lunch and tea are in Room K2.40.\n\nWednesdayThursdayFriday\n\n\n\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n  \n  \n  \n    10:30 - 11:00\nRegistration and coffee\n\n\n\n    11:00 - 12.00\nKeynote 1\n\n\n\n    \nDean Eckles\n\nLearning from randomized interventions in social media\nHow should we reason about the effects of interventions in social media? What effect sizes should be expected from such changes to algorithms and content? And, given the fundamentally social nature of these services, what conclusions can we draw from individual-level experiments? I will comment on the published results from prominent, recent experiments on Facebook and Instagram conducted during the 2020 US Elections. I will also draw on two new field experiments on Facebook \\((N&gt;3.3\\times 10^7)\\) and Twitter \\((N&gt;7.5 \\times 10^4)\\), each randomizing exposure to advertising featuring content-general messages reminding people to think about accuracy.[Paper]\n\n    12:00 - 13:30\nLunch\n\n\n\n    13:30 - 14:30\nKeynote 2\n\n\n\n    \nNathaniel Stevens\nUniversity of Waterloo\nDesign and Analysis of Network A/B Tests with General Additive Network Effect Models\nAs a means of continual improvement and innovation, online controlled experiments are widely used by internet and technology companies to test and evaluate product changes, and new features, and to ensure that user feedback drives decisions. This is true of companies like LinkedIn, Facebook, and X, large online social networks. However, experiments on networks are complicated by the fact that the stable unit treatment value assumption (SUTVA) no longer holds. Due to the interconnectivity of users in these networks, a user’s outcome may be influenced by their own treatment assignment as well as the treatment assignment of those they are socially connected with. The design and analysis of the experiment must account for this. The general additive network effect (GANE) family of models is proposed to jointly and flexibly model treatment and network effects. Experimental design and analysis considerations are discussed in the context of the proposed family of models.\nCollaborators:\n\nTrang Bui (University of Waterloo)\nStefan Steiner(University of Waterloo)\n\n\n    14:30 - 15.00\nTea\n\n\n\n    15:00 - 17:00\nInvited session 1\n\n\n\n    \nAlessio Zanga\nUniversity of Milano - Bicocca\nFederated Causal Discovery with Missing Data in a Multicentric Study on Endometrial Cancer\nCausal discovery is the task of learning a causal graph representing the cause-effect relationships. Being able to establish causal dependencies is crucial in several applied domains, especially when the decision-making policy needs to be explainable, as in the case of medicine and healthcare. In these settings, small sample size and missing data call for federated approaches to take advantage of the information distributed across multiple sources. In this work, we introduce a novel federated causal discovery algorithm capable of pooling together information from multiple sources with heterogeneous missing data distributions. In particular, we propose a score-based approach that learns a global causal graph while taking into account local missingness mechanisms and prior knowledge. We applied the proposed algorithm on a real-world multicentric study on endometrial cancer, validating the obtained causal graph through quantitative analyses and clinical literature. The federated methodology showed promising results in recovering the underlying causal graph, especially in the presence of data missing not at random.\n\n    \nKirsten Schorning\nTechnische Universitt Dortmund\nOptimal Designs For State Estimation In Networks\nWe consider the problem of estimating the expected states in networks, where observations are given by repeated measurements of the random states at the nodes. The choice of the sensors directly influences the quality of the measurements at the different nodes. During the talk, we address the problem of optimally allocating different sensors to the nodes using optimal design theory. Hereby, we assume two models of different complexity.\nIn the first model, the states of the different nodes are assumed to be independent from time. The design question is then to determine which nodes need greater precision of the measurements than others. Here, we derive explicitly A-optimal designs for different networks, e.g., a star network.\nIn the second model, the first model is extended to time-dependent states; in particular, we model the states using time-dependent functions. Then, the design problem concises the optimal allocation of different measurement devices and the different time points at which measurements should be taken. Both analytical and numerical results are provided for the second model using A-optimality.\n\n    \nBen Parker\nBrunel University\nDesign of Experiments for autoregressive networks\n\n    17:00\nClose of the day\n\n\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n  \n  \n  \n    09:30-10:30\nKeynote 3\n\n\n\n    \nAlexander Volfovsky\nDuke University\n Neighborhood Adaptive Estimators for Causal Inference under Network Interference\n\n    10:30-11:00\nCoffee\n\n\n\n    11:00-12:30\nInvited industry session\n\n\n\n    \nEleni Kalfountzou\nProcter & Gamble\nExperimentation in the FMCG industry - when A/B testing is not enough\n\n    \nLorenzo Masoero\nAmazon\n\n\n    12:30-14:00\nLunch\n\n\n\n    14:00-15:20\nInvited session 2\n\n\n\n    \nTim Waite\nUniversity of Manchester\nSequential Bayesian design with Laplace-parameterized policies\nIn the past few years policy-based approaches have been developed as a method for sequential Bayesian design, building on ideas from dynamic programming and deep reinforcement learning. The idea is to construct in advance a policy, i.e. a mapping from the current knowledge state to the next set of experimental conditions at which to observe a response. This policy is to be constructed in such a way as to maximize the ultimate expected utility, e.g. the expected Shannon information gain, after all experiments have been completed. This is usually done by taking the policy to be a neural network, and optimizing its weights. However, a key question in policy-based approaches is how to represent the knowledge state, i.e. what to use as the input to the policy network. It is clear the knowledge state is completely specified by the posterior distribution, and so an attractive choice would be an approximation to the posterior, especially one with only a few parameters which could then serve as inputs to the policy network. In this talk we discuss the use of the Laplace approximation to the posterior as the knowledge representation, and develop the methodology needed to train policies based on Laplace representations. \n\n    \nWerner Müller\nJohannes Kepler University Linz\nA practical guide to optimal design of experiments under correlation\n\n    15:20-16:00\nTea\n\n\n\n    16:00-17:00\nPanel discussion\nThe future of networked experiments\n\n\n    \nChair: Steve Gilmour\nKing's College London\n\nPanelists: Dean Eckles, Nathaniel Stevens, Alexander Volfovsky, Eleni Kalfountzou, Lorenzo Masoero, Rosemary Bailey\n\n    17:00-18:00\nReception\n\n\n\n    18:00\nClose of the day\n\n\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n  \n  \n  \n    09:30-10:30\nKeynote 4\n\n\n\n    \nRosemary Bailey\nUniversity of St Andrews\nDesigns on strongly-regular graphs\nMost networks can be regarded as graphs.  Some particularly nice graphs are the strongly-regular graphs.  The edges and non-edges of such graphs form the\nassociate classes of an association scheme.  The corresponding Bose-Mesner algebra\n(linear combinations of the adjacency matrices) has three common eigenspaces, one of which consists of the constant vectors.\nIn classical work on design of experiments, the experimental units are grouped into \\(b\\) blocks of size \\(k\\). There are three common eigenspaces. One consists of the constant vectors (it has dimension \\(1\\)); one consists of vectors which are constant on each block and whose entries sum to zero (it has dimension \\(b-1\\); the third is the orthogonal complement of these two (it has dimension \\(b(k-1)\\).\nIn some experiments, the experimental units are all pairs of individuals who have to undertake a given task together. If all such pairs are used exactly once each, then the set of pairs forms a triangular association scheme. If there are \\(n\\) individuals then there are \\(N = n(n − 1)/2\\) such pairs. The corresponding Bose–Mesner algebra has three common eigenspaces. One consists of the constant vectors (it has dimension \\(1\\));\none consists of linear combinations of the indicator vectors of individuals, constrained so that the entries sum to zero (it has dimension \\(n−1\\)); the third is the orthogonal complement of these two (it has dimension \\(N − n\\)).\nIn both cases, we assume that the variance–covariance matrix \\(C\\) of the responses to the experiment is an unknown linear combination of the matrices of projection onto these eigenspaces.\nTwo types of block design are particularly important. In balanced block designs, the variance of the estimated difference between any two treatments is the same, no matter what the eigenvalues of \\(C\\) are. In orthogonal block designs, the linear combination of responses which gives the best unbiased estimator of any difference between treatments does not depend on what the eigenvalues of \\(C\\) are. Such designs are often said to have commutative orthogonal block structure.\nIn this talk I will give some constructions for balanced designs and some for designs\nwhich have commutative orthogonal block structure, in each scenario.\nThis is joint work with P. Cameron (University of St Andrews) and D. Ferreira, S. S. Ferreira and C. Nunes (Universidade de Beira Interior).\n\n    10:30-11:00\nCoffee\n\n\n\n    11:00-12:15\nInvited session 3\n\n\n\n    \nFrancesca Panero\nSapienza University\nModelling sparse networks with Bayesian nonparametrics\nThe graphex is a statistical framework to model random graphs, originally introduced in Caron and Fox (2017). It is particularly flexible, in that by using carefully chosen Bayesian nonparametric priors it allows us to describe dense and sparse networks, different degree distributions (power-law included) and positive clustering. After introducing the general graphex framework and its asymptotic properties, I will explain how we model sparse networks embedded in a latent space and use this framework to uncover structures underlying mobility patterns. I will conclude by introducing a different variety of the graphex that allows to describe dynamic networks with overlapping communities.\n\n    \nRuben Sanchez-Garcia\nUniversity of Southampton\nExploiting symmetry in network analysis\nNetwork models of real-world complex systems typically include a large amount of structural redundancy, which manifest itself as symmetries of the network. Network symmetries are inherited by any structural measure on the network, and thus exploited in any network analysis. I will explain the effect of network symmetry on arbitrary network measures and show how this can be exploited in practice in a number of ways, from redundancy compression to computational reduction. Computing network symmetries is very efficient in practice, and we test real-world examples up to several million nodes. Since network models are ubiquitous in the Applied Sciences, our results are widely applicable.\n\n    12:15-12:30\nConcluding remarks\n\n\n\n    12:30-14:00\nLunch\n\n\n\n    14:00\nClose of the workshop"
  },
  {
    "objectID": "programme.html#programme",
    "href": "programme.html#programme",
    "title": "Design and Analysis of Networked Experiments 2024",
    "section": "",
    "text": "All scientific sessions are in the River room. Coffee, lunch and tea are in Room K2.40.\n\nWednesdayThursdayFriday\n\n\n\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n  \n  \n  \n    10:30 - 11:00\nRegistration and coffee\n\n\n\n    11:00 - 12.00\nKeynote 1\n\n\n\n    \nDean Eckles\n\nLearning from randomized interventions in social media\nHow should we reason about the effects of interventions in social media? What effect sizes should be expected from such changes to algorithms and content? And, given the fundamentally social nature of these services, what conclusions can we draw from individual-level experiments? I will comment on the published results from prominent, recent experiments on Facebook and Instagram conducted during the 2020 US Elections. I will also draw on two new field experiments on Facebook \\((N&gt;3.3\\times 10^7)\\) and Twitter \\((N&gt;7.5 \\times 10^4)\\), each randomizing exposure to advertising featuring content-general messages reminding people to think about accuracy.[Paper]\n\n    12:00 - 13:30\nLunch\n\n\n\n    13:30 - 14:30\nKeynote 2\n\n\n\n    \nNathaniel Stevens\nUniversity of Waterloo\nDesign and Analysis of Network A/B Tests with General Additive Network Effect Models\nAs a means of continual improvement and innovation, online controlled experiments are widely used by internet and technology companies to test and evaluate product changes, and new features, and to ensure that user feedback drives decisions. This is true of companies like LinkedIn, Facebook, and X, large online social networks. However, experiments on networks are complicated by the fact that the stable unit treatment value assumption (SUTVA) no longer holds. Due to the interconnectivity of users in these networks, a user’s outcome may be influenced by their own treatment assignment as well as the treatment assignment of those they are socially connected with. The design and analysis of the experiment must account for this. The general additive network effect (GANE) family of models is proposed to jointly and flexibly model treatment and network effects. Experimental design and analysis considerations are discussed in the context of the proposed family of models.\nCollaborators:\n\nTrang Bui (University of Waterloo)\nStefan Steiner(University of Waterloo)\n\n\n    14:30 - 15.00\nTea\n\n\n\n    15:00 - 17:00\nInvited session 1\n\n\n\n    \nAlessio Zanga\nUniversity of Milano - Bicocca\nFederated Causal Discovery with Missing Data in a Multicentric Study on Endometrial Cancer\nCausal discovery is the task of learning a causal graph representing the cause-effect relationships. Being able to establish causal dependencies is crucial in several applied domains, especially when the decision-making policy needs to be explainable, as in the case of medicine and healthcare. In these settings, small sample size and missing data call for federated approaches to take advantage of the information distributed across multiple sources. In this work, we introduce a novel federated causal discovery algorithm capable of pooling together information from multiple sources with heterogeneous missing data distributions. In particular, we propose a score-based approach that learns a global causal graph while taking into account local missingness mechanisms and prior knowledge. We applied the proposed algorithm on a real-world multicentric study on endometrial cancer, validating the obtained causal graph through quantitative analyses and clinical literature. The federated methodology showed promising results in recovering the underlying causal graph, especially in the presence of data missing not at random.\n\n    \nKirsten Schorning\nTechnische Universitt Dortmund\nOptimal Designs For State Estimation In Networks\nWe consider the problem of estimating the expected states in networks, where observations are given by repeated measurements of the random states at the nodes. The choice of the sensors directly influences the quality of the measurements at the different nodes. During the talk, we address the problem of optimally allocating different sensors to the nodes using optimal design theory. Hereby, we assume two models of different complexity.\nIn the first model, the states of the different nodes are assumed to be independent from time. The design question is then to determine which nodes need greater precision of the measurements than others. Here, we derive explicitly A-optimal designs for different networks, e.g., a star network.\nIn the second model, the first model is extended to time-dependent states; in particular, we model the states using time-dependent functions. Then, the design problem concises the optimal allocation of different measurement devices and the different time points at which measurements should be taken. Both analytical and numerical results are provided for the second model using A-optimality.\n\n    \nBen Parker\nBrunel University\nDesign of Experiments for autoregressive networks\n\n    17:00\nClose of the day\n\n\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n  \n  \n  \n    09:30-10:30\nKeynote 3\n\n\n\n    \nAlexander Volfovsky\nDuke University\n Neighborhood Adaptive Estimators for Causal Inference under Network Interference\n\n    10:30-11:00\nCoffee\n\n\n\n    11:00-12:30\nInvited industry session\n\n\n\n    \nEleni Kalfountzou\nProcter & Gamble\nExperimentation in the FMCG industry - when A/B testing is not enough\n\n    \nLorenzo Masoero\nAmazon\n\n\n    12:30-14:00\nLunch\n\n\n\n    14:00-15:20\nInvited session 2\n\n\n\n    \nTim Waite\nUniversity of Manchester\nSequential Bayesian design with Laplace-parameterized policies\nIn the past few years policy-based approaches have been developed as a method for sequential Bayesian design, building on ideas from dynamic programming and deep reinforcement learning. The idea is to construct in advance a policy, i.e. a mapping from the current knowledge state to the next set of experimental conditions at which to observe a response. This policy is to be constructed in such a way as to maximize the ultimate expected utility, e.g. the expected Shannon information gain, after all experiments have been completed. This is usually done by taking the policy to be a neural network, and optimizing its weights. However, a key question in policy-based approaches is how to represent the knowledge state, i.e. what to use as the input to the policy network. It is clear the knowledge state is completely specified by the posterior distribution, and so an attractive choice would be an approximation to the posterior, especially one with only a few parameters which could then serve as inputs to the policy network. In this talk we discuss the use of the Laplace approximation to the posterior as the knowledge representation, and develop the methodology needed to train policies based on Laplace representations. \n\n    \nWerner Müller\nJohannes Kepler University Linz\nA practical guide to optimal design of experiments under correlation\n\n    15:20-16:00\nTea\n\n\n\n    16:00-17:00\nPanel discussion\nThe future of networked experiments\n\n\n    \nChair: Steve Gilmour\nKing's College London\n\nPanelists: Dean Eckles, Nathaniel Stevens, Alexander Volfovsky, Eleni Kalfountzou, Lorenzo Masoero, Rosemary Bailey\n\n    17:00-18:00\nReception\n\n\n\n    18:00\nClose of the day\n\n\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n  \n  \n  \n    09:30-10:30\nKeynote 4\n\n\n\n    \nRosemary Bailey\nUniversity of St Andrews\nDesigns on strongly-regular graphs\nMost networks can be regarded as graphs.  Some particularly nice graphs are the strongly-regular graphs.  The edges and non-edges of such graphs form the\nassociate classes of an association scheme.  The corresponding Bose-Mesner algebra\n(linear combinations of the adjacency matrices) has three common eigenspaces, one of which consists of the constant vectors.\nIn classical work on design of experiments, the experimental units are grouped into \\(b\\) blocks of size \\(k\\). There are three common eigenspaces. One consists of the constant vectors (it has dimension \\(1\\)); one consists of vectors which are constant on each block and whose entries sum to zero (it has dimension \\(b-1\\); the third is the orthogonal complement of these two (it has dimension \\(b(k-1)\\).\nIn some experiments, the experimental units are all pairs of individuals who have to undertake a given task together. If all such pairs are used exactly once each, then the set of pairs forms a triangular association scheme. If there are \\(n\\) individuals then there are \\(N = n(n − 1)/2\\) such pairs. The corresponding Bose–Mesner algebra has three common eigenspaces. One consists of the constant vectors (it has dimension \\(1\\));\none consists of linear combinations of the indicator vectors of individuals, constrained so that the entries sum to zero (it has dimension \\(n−1\\)); the third is the orthogonal complement of these two (it has dimension \\(N − n\\)).\nIn both cases, we assume that the variance–covariance matrix \\(C\\) of the responses to the experiment is an unknown linear combination of the matrices of projection onto these eigenspaces.\nTwo types of block design are particularly important. In balanced block designs, the variance of the estimated difference between any two treatments is the same, no matter what the eigenvalues of \\(C\\) are. In orthogonal block designs, the linear combination of responses which gives the best unbiased estimator of any difference between treatments does not depend on what the eigenvalues of \\(C\\) are. Such designs are often said to have commutative orthogonal block structure.\nIn this talk I will give some constructions for balanced designs and some for designs\nwhich have commutative orthogonal block structure, in each scenario.\nThis is joint work with P. Cameron (University of St Andrews) and D. Ferreira, S. S. Ferreira and C. Nunes (Universidade de Beira Interior).\n\n    10:30-11:00\nCoffee\n\n\n\n    11:00-12:15\nInvited session 3\n\n\n\n    \nFrancesca Panero\nSapienza University\nModelling sparse networks with Bayesian nonparametrics\nThe graphex is a statistical framework to model random graphs, originally introduced in Caron and Fox (2017). It is particularly flexible, in that by using carefully chosen Bayesian nonparametric priors it allows us to describe dense and sparse networks, different degree distributions (power-law included) and positive clustering. After introducing the general graphex framework and its asymptotic properties, I will explain how we model sparse networks embedded in a latent space and use this framework to uncover structures underlying mobility patterns. I will conclude by introducing a different variety of the graphex that allows to describe dynamic networks with overlapping communities.\n\n    \nRuben Sanchez-Garcia\nUniversity of Southampton\nExploiting symmetry in network analysis\nNetwork models of real-world complex systems typically include a large amount of structural redundancy, which manifest itself as symmetries of the network. Network symmetries are inherited by any structural measure on the network, and thus exploited in any network analysis. I will explain the effect of network symmetry on arbitrary network measures and show how this can be exploited in practice in a number of ways, from redundancy compression to computational reduction. Computing network symmetries is very efficient in practice, and we test real-world examples up to several million nodes. Since network models are ubiquitous in the Applied Sciences, our results are widely applicable.\n\n    12:15-12:30\nConcluding remarks\n\n\n\n    12:30-14:00\nLunch\n\n\n\n    14:00\nClose of the workshop"
  },
  {
    "objectID": "location.html",
    "href": "location.html",
    "title": "Design and Analysis of Networked Experiments 2024",
    "section": "",
    "text": "The workshop will be held at the Strand Campus of King’s College London. Scientific sessions will be held in the River Room."
  },
  {
    "objectID": "location.html#location",
    "href": "location.html#location",
    "title": "Design and Analysis of Networked Experiments 2024",
    "section": "",
    "text": "The workshop will be held at the Strand Campus of King’s College London. Scientific sessions will be held in the River Room."
  }
]